### **Concurrency Limiter in ASP.NET Core**

The **concurrency limiter** is a rate-limiting algorithm that controls the **number of concurrent requests** being processed at any given time. Unlike other limiters that impose caps on the total number of requests over a time window, the concurrency limiter focuses solely on controlling simultaneous active requests.

---

### **How the Concurrency Limiter Works**

1. **Permit Limit:**
   - Defines the maximum number of concurrent requests that can be processed simultaneously.
   - Each incoming request reduces the available permits by one.

2. **Request Completion:**
   - When a request is completed, its permit is released, and the count of available permits is incremented by one.

3. **Queueing:**
   - If the number of concurrent requests exceeds the **permit limit**, excess requests are queued (if queuing is enabled).
   - Queued requests are processed based on the **queue processing order**:
     - **OldestFirst:** Processes requests in the order they were received.
     - **NewestFirst:** Processes the most recent request first.

4. **Queue Limit:**
   - Specifies the maximum number of requests that can be queued when the concurrency limit is reached.
   - If the queue is full, new requests are rejected.

---

### **Code Example: Concurrency Limiter**

#### **Configuration Overview:**
- **Permit Limit:** 3 (maximum concurrent requests allowed).
- **Queue Limit:** 5 (maximum queued requests).
- **Queue Processing Order:** `OldestFirst`.

#### **Code:**

```csharp
using Microsoft.AspNetCore.RateLimiting;
using System.Threading.RateLimiting;
using WebRateLimitAuth.Models;

var builder = WebApplication.CreateBuilder(args);

var concurrencyPolicy = "Concurrency";
var myOptions = new MyRateLimitOptions();
builder.Configuration.GetSection(MyRateLimitOptions.MyRateLimit).Bind(myOptions);

// Configure the Concurrency Limiter
builder.Services.AddRateLimiter(_ => _
    .AddConcurrencyLimiter(policyName: concurrencyPolicy, options =>
    {
        options.PermitLimit = myOptions.PermitLimit; // Max concurrent requests
        options.QueueProcessingOrder = QueueProcessingOrder.OldestFirst; // Process oldest requests first
        options.QueueLimit = myOptions.QueueLimit; // Max number of queued requests
    }));

var app = builder.Build();

app.UseRateLimiter(); // Enable rate limiting middleware

static string GetTicks() => (DateTime.Now.Ticks & 0x11111).ToString("00000");

// Endpoint using the concurrency limiter
app.MapGet("/", async () =>
{
    await Task.Delay(500); // Simulate processing time
    return Results.Ok($"Concurrency Limiter {GetTicks()}");
}).RequireRateLimiting(concurrencyPolicy);

app.Run();
```

---

### **Explanation of Code**

1. **Rate Limiter Configuration:**
   - The concurrency limiter is configured using `AddConcurrencyLimiter`.
   - Options include:
     - **PermitLimit:** The maximum number of concurrent requests allowed.
     - **QueueLimit:** The maximum number of queued requests.
     - **QueueProcessingOrder:** Defines the order in which queued requests are processed.

2. **Middleware Placement:**
   - `UseRateLimiter` integrates the rate limiter middleware into the request pipeline.
   - The limiter is attached to the endpoint using `RequireRateLimiting`.

3. **Request Handling:**
   - Requests exceeding the concurrency limit are queued if space is available.
   - If the queue is full, new requests are immediately rejected.

4. **Simulated Delay:**
   - A `Task.Delay(500)` simulates 500 milliseconds of processing time, demonstrating how the limiter controls concurrency.

---

### **Configuration-Driven Approach**

#### **AppSettings (`appsettings.json`):**

```json
{
  "MyRateLimitOptions": {
    "PermitLimit": 3,
    "QueueLimit": 5,
    "QueueProcessingOrder": "OldestFirst"
  }
}
```

#### **Benefits of External Configuration:**
- Makes it easy to adjust concurrency limits and queue settings.
- Ensures consistency across environments.
- Supports runtime adjustments without modifying code.

---

### **Concurrency Limiter Example in Action**

#### **Scenario:**
- **Permit Limit:** 3
- **Queue Limit:** 5

#### **Request Behavior:**

1. First **3 requests** are processed immediately (consume the 3 available permits).
2. Next **5 requests** are queued (within the queue limit).
3. Any additional requests are rejected until permits are released or queue space is available.

---

### **Concurrency Limiter Key Features**

1. **Control Over Simultaneous Requests:**
   - Ensures the system doesn't become overloaded by limiting concurrent processing.
   
2. **Request Queueing:**
   - Prevents request rejection by queuing them when limits are exceeded.

3. **Queue Management:**
   - Flexible queue handling via `OldestFirst` or `NewestFirst` policies.

4. **No Time-Based Limits:**
   - Unlike other limiters, the concurrency limiter doesn't enforce time-based restrictions.

---

### **Concurrency Limiter vs. Other Limiters**

| **Feature**              | **Concurrency Limiter**                              | **Fixed/Sliding Window Limiter**                   | **Token Bucket Limiter**                         |
|--------------------------|-----------------------------------------------------|---------------------------------------------------|-------------------------------------------------|
| **Focus**                | Controls simultaneous active requests               | Limits total requests over a time window          | Limits requests by tokens replenished per time  |
| **Time Window**          | Not applicable                                      | Fixed/sliding time windows                        | Fixed replenishment periods                     |
| **Burst Handling**       | Supports simultaneous burst processing              | No burst handling                                 | Allows bursts within token limits               |
| **Queueing**             | Controls how excess requests are queued             | May queue depending on configuration              | May queue depending on configuration            |

---

### **Summary**

The **concurrency limiter** in ASP.NET Core is ideal for controlling the number of simultaneous requests being processed, providing:
- Protection against resource exhaustion.
- Fine-grained control of active request limits.
- Flexible queueing and processing strategies.

It is particularly useful for scenarios like database access or external API calls, where simultaneous requests need to be capped to prevent system overload.